{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 and Weather Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "- *tensorflow* for tensor processing\n",
    "- *keras* for simplified tensor processing\n",
    "- *matplotlib* for rendering data visually\n",
    "- *numpy* for array processing\n",
    "- *pandas* for rendering tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Management\n",
    "import os\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Processing\n",
    "import numpy\n",
    "import pandas\n",
    "import data_processing\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The goal of this work is to determine whether or not weather patterns should be considered as supporting input data when making predictions about new daily COVID-19 cases within a given geographical space. Using census, weather, and COVID-19 datasets provided by the Urban Sustain project, the authors attempt to quantify the correlation between particular weather patterns and COVID-19 transmission events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEVELOPER NOTE:** Download the five required datasets from Urban Sustain and place them in the cloned repository at ```./data/```. These datasets are also available at a shared OneDrive folder. This logic expects that these files exist at relative path ```../data/``` with respect to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by defining a path to our data directory and a list of the datasets that we expect to find there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '../data/'\n",
    "expectedDatasets = [\n",
    "    'covid_county.Colorado.zip',\n",
    "    'neon_2d_wind.Colorado.zip',\n",
    "    'neon_barometric_pressure.Colorado.zip',\n",
    "    'neon_single_asp_air_temperature.Colorado.zip',\n",
    "    'svi_county_GISJOIN.Colorado.zip'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will attempt to extract each of these archived datasets into a subdirectory within the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datasetName in expectedDatasets:\n",
    "    try:\n",
    "        with ZipFile(dataPath + datasetName, 'r') as currentzip:\n",
    "            datasetNameTokens = datasetName.split('.')\n",
    "            datasetNameTokens.remove('zip')\n",
    "            targetDirectory = dataPath + '.'.join(datasetNameTokens)\n",
    "            if not os.path.exists(targetDirectory):\n",
    "                Path(targetDirectory).mkdir()\n",
    "            currentzip.extractall(targetDirectory)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Unable to open \" + datasetName + \" at path \" + dataPath + datasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Create Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39936 entries, 0 to 39935\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   GISJOIN                 39936 non-null  object\n",
      " 1   dateString              39936 non-null  object\n",
      " 2   county                  39936 non-null  object\n",
      " 3   state                   39936 non-null  object\n",
      " 4   totalCaseCount          39936 non-null  int64 \n",
      " 5   newCaseCount            39936 non-null  int64 \n",
      " 6   totalDeathCount         39936 non-null  int64 \n",
      " 7   newDeathCount           39936 non-null  int64 \n",
      " 8   _id.$oid                39936 non-null  object\n",
      " 9   epoch_time.$numberLong  39936 non-null  object\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1391744 entries, 0 to 1391743\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   site                    1391744 non-null  object \n",
      " 1   startDateTime           1391744 non-null  object \n",
      " 2   endDateTime             1391744 non-null  object \n",
      " 3   windSpeedMean           1391744 non-null  float64\n",
      " 4   windSpeedMinimum        1391744 non-null  float64\n",
      " 5   windSpeedMaximum        1391744 non-null  float64\n",
      " 6   windSpeedVariance       1391744 non-null  float64\n",
      " 7   windSpeedNumPts         1391744 non-null  int64  \n",
      " 8   windSpeedExpUncert      1391744 non-null  float64\n",
      " 9   windSpeedStdErMean      1391744 non-null  float64\n",
      " 10  windSpeedFinalQF        1391744 non-null  int64  \n",
      " 11  windDirMean             1391744 non-null  float64\n",
      " 12  windDirVariance         1391744 non-null  float64\n",
      " 13  windDirNumPts           1391744 non-null  int64  \n",
      " 14  windDirExpUncert        1391744 non-null  float64\n",
      " 15  windDirStdErMean        1391744 non-null  float64\n",
      " 16  windDirFinalQF          1391744 non-null  int64  \n",
      " 17  _id.$oid                1391744 non-null  object \n",
      " 18  epoch_time.$numberLong  1391744 non-null  object \n",
      "dtypes: float64(10), int64(4), object(5)\n",
      "memory usage: 201.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311270 entries, 0 to 1311269\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   site                    1311270 non-null  object \n",
      " 1   startDateTime           1311270 non-null  object \n",
      " 2   endDateTime             1311270 non-null  object \n",
      " 3   tempSingleMean          1311270 non-null  float64\n",
      " 4   tempSingleMinimum       1311270 non-null  float64\n",
      " 5   tempSingleMaximum       1311270 non-null  float64\n",
      " 6   tempSingleVariance      1311270 non-null  float64\n",
      " 7   tempSingleNumPts        1311270 non-null  int64  \n",
      " 8   tempSingleExpUncert     1311270 non-null  float64\n",
      " 9   tempSingleStdErMean     1311270 non-null  float64\n",
      " 10  finalQF                 1311270 non-null  int64  \n",
      " 11  _id.$oid                1311270 non-null  object \n",
      " 12  epoch_time.$numberLong  1311270 non-null  object \n",
      "dtypes: float64(6), int64(2), object(5)\n",
      "memory usage: 130.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "expected_directories = {\n",
    "    'covid_county': os.path.join(dataPath, 'covid_county.Colorado'),\n",
    "    'neon_2d_wind': os.path.join(dataPath, 'neon_2d_wind.Colorado'),\n",
    "    'neon_single_asp_air_temperature': os.path.join(dataPath, 'neon_single_asp_air_temperature.Colorado'),\n",
    "    'neon_barometric_pressure': os.path.join(dataPath, 'neon_barometric_pressure.Colorado'),\n",
    "    'svi_county_GISJOIN': os.path.join(dataPath, 'svi_county_GISJOIN.Colorado')\n",
    "}\n",
    "covid_df = data_processing.load_flattened_datasets(\n",
    "    os.path.join(expected_directories['covid_county'], 'data.json'),\n",
    "    os.path.join(expected_directories['covid_county'], 'fieldLabels.json'),\n",
    "    os.path.join(expected_directories['covid_county'], 'linkedGeometry.json'),\n",
    "    join_on_key='GISJOIN')\n",
    "wind_df = data_processing.load_flattened_datasets(\n",
    "    os.path.join(expected_directories['neon_2d_wind'], 'data.json'),\n",
    "    os.path.join(expected_directories['neon_2d_wind'], 'fieldLabels.json'),\n",
    "    os.path.join(expected_directories['neon_2d_wind'], 'linkedGeometry.json'),\n",
    "    join_on_key='site')\n",
    "air_temp_df = data_processing.load_flattened_datasets(\n",
    "    os.path.join(expected_directories['neon_single_asp_air_temperature'], 'data.json'),\n",
    "    os.path.join(expected_directories['neon_single_asp_air_temperature'], 'fieldLabels.json'),\n",
    "    os.path.join(expected_directories['neon_single_asp_air_temperature'], 'linkedGeometry.json'),\n",
    "    join_on_key='site')\n",
    "air_presssure_df = data_processing.load_flattened_datasets(\n",
    "    os.path.join(expected_directories['neon_barometric_pressure'], 'data.json'),\n",
    "    os.path.join(expected_directories['neon_barometric_pressure'], 'fieldLabels.json'),\n",
    "    os.path.join(expected_directories['neon_barometric_pressure'], 'linkedGeometry.json'),\n",
    "    join_on_key='site')\n",
    "county_df = data_processing.load_flattened_datasets(\n",
    "    os.path.join(expected_directories['svi_county_GISJOIN'], 'data.json'),\n",
    "    os.path.join(expected_directories['svi_county_GISJOIN'], 'fieldLabels.json'),\n",
    "    os.path.join(expected_directories['svi_county_GISJOIN'], 'linkedGeometry.json'),\n",
    "    join_on_key='GISJOIN')\n",
    "\n",
    "print(covid_df.info)\n",
    "print(wind_df.info)\n",
    "print(air_temp_df.info)\n",
    "print(air_presssure_df.info)\n",
    "print(county_df.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "**Authors:** Kyle Bassignani, Jeff Borgerson, and Christian Westbrook  \n",
    "**Updated On:** 2021-11-12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
